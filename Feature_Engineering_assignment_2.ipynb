{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering_assignment_2\n"
      ],
      "metadata": {
        "id": "hiZHxu7U2lb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcGtqbd_2ZXH"
      },
      "outputs": [],
      "source": [
        "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
        "\n",
        "Min-Max Scaling:\n",
        "\n",
        "Definition: Min-Max scaling (also known as normalization) rescales the features to a fixed range, typically [0, 1].\n",
        "It transforms the values by subtracting the minimum value and then dividing by the range (maximum - minimum).\n",
        "\n",
        "Application Example: Suppose you have a feature representing house prices with values ranging from $100,000 to $1,000,000.\n",
        "Applying Min-Max scaling would transform these values to the range [0, 1], making them more suitable for models that are sensitive to the scale of numeric input features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
        "\n",
        "Unit Vector Scaling:\n",
        "\n",
        "Definition: Unit vector scaling (or normalization) scales the vector of feature values to have unit norm, typically using the L2 norm (Euclidean norm).\n",
        "Application Example: Consider a dataset with features like age, income, and education level.\n",
        "Unit vector scaling would normalize these features to unit norm, preserving the direction of the data vectors and making them comparable in terms of their overall magnitude."
      ],
      "metadata": {
        "id": "EhVGD3V425nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3. What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
        "\n",
        "PCA (Principal Component Analysis):\n",
        "\n",
        "Definition: PCA is a dimensionality reduction technique that transforms high-dimensional data into a lower-dimensional space by identifying a new set of variables called principal components.\n",
        "Application Example: Suppose you have a dataset with many correlated features describing customer behavior.\n",
        "PCA can be applied to reduce the dimensionality by identifying principal components that capture the maximum variance in the data, thus reducing redundancy and computational complexity."
      ],
      "metadata": {
        "id": "XLlPUYxI25qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
        "\n",
        "PCA for Feature Extraction:\n",
        "\n",
        "Relationship: PCA can be used for feature extraction by transforming the original features into a smaller set of principal components that retain the most important information from the original data.\n",
        "Application Example: In a dataset containing image features (e.g., pixel values),\n",
        "PCA can be applied to extract principal components that represent patterns or structures in the images, such as edges or textures, thereby reducing the dimensionality of the feature space while preserving relevant information."
      ],
      "metadata": {
        "id": "NjyluJaW25ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
        "\n",
        "Application: Apply Min-Max scaling to normalize each feature (price, rating, delivery time) to a range of [0, 1].\n",
        "This ensures that features with different scales are standardized and have equal importance during model training.\n",
        "For example, if price ranges from $5 to $50, rating ranges from 1 to 5, and delivery time ranges from 10 to 60 minutes, Min-Max scaling would transform these ranges to [0, 1]"
      ],
      "metadata": {
        "id": "TBkGXsIN25v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
        "\n",
        "Application: Apply PCA to the dataset containing stock features to reduce its dimensionality. PCA would identify the principal components that explain the maximum variance in the stock data.\n",
        "By selecting a smaller number of principal components (e.g., top 5 or 10), you can capture the most significant patterns and reduce noise or redundant information in the dataset."
      ],
      "metadata": {
        "id": "XaA_cO6j25yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
        "\n",
        "Selection Criteria: Choose the number of principal components based on the cumulative explained variance ratio. Aim to retain a sufficient percentage (e.g., 95%) of the total variance while reducing dimensionality.\n",
        "In practice, this might involve experimenting with different numbers of components and evaluating model performance."
      ],
      "metadata": {
        "id": "YI47VD5Y250l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABjM3wwg253N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZzzmW4f255V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUVUFwL9258L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyhoSWLt25_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}