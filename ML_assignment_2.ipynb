{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning assignment_2\n"
      ],
      "metadata": {
        "id": "hiZHxu7U2lb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcGtqbd_2ZXH"
      },
      "outputs": [],
      "source": [
        "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
        "\n",
        "Overfitting: Overfitting occurs when a model learns the details and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This often results in a model that performs very well on training data but poorly on unseen test data.\n",
        "\n",
        "Consequences: High variance, poor generalization to new data, and potential inability to capture the underlying trend or pattern due to noise.\n",
        "\n",
        "Mitigation: Techniques to mitigate overfitting include:\n",
        "\n",
        "Cross-validation: Use techniques like k-fold cross-validation to assess model performance on unseen data.\n",
        "Regularization: Apply penalties to the complexity of the model to discourage overfitting.\n",
        "Feature selection/reduction: Selecting relevant features or reducing the number of features can help simplify the model.\n",
        "Early stopping: Stopping the training process before the model starts to overfit based on performance metrics on a validation set.\n",
        "Underfitting: Underfitting occurs when a model is too simple to capture the underlying structure of the data.\n",
        "This results in a model that performs poorly on both training and test data.\n",
        "\n",
        "Consequences: High bias, inability to capture important patterns, and oversimplified model that does not learn well from the data.\n",
        "\n",
        "Mitigation: Techniques to mitigate underfitting include:\n",
        "Increase model complexity: Use more complex models or algorithms that can capture the underlying patterns in the data.\n",
        "Add more features: Introduce more relevant features to the model.\n",
        "Reduce regularization: If regularization is too strong, it may lead to underfitting; hence, reducing regularization can help.\n",
        "Increase training time: Sometimes, more training epochs or iterations may help the model learn better."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q2: How can we reduce overfitting? Explain in brief.\n",
        "\n",
        "To reduce overfitting, you can:\n",
        "\n",
        "Use regularization techniques such as L1 (Lasso) and L2 (Ridge) regularization to penalize large coefficients.\n",
        "Cross-validation to evaluate model performance and tune hyperparameters.\n",
        "Use dropout or ensemble methods like bagging and boosting to improve generalization.\n",
        "Reduce model complexity by feature selection/reduction or using simpler models."
      ],
      "metadata": {
        "id": "EhVGD3V425nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
        "\n",
        "Underfitting occurs when a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and test data. Scenarios where underfitting can occur include:\n",
        "\n",
        "Using a linear model for nonlinear data.\n",
        "Insufficient training of the model (too few epochs or iterations).\n",
        "Using a model with too few parameters relative to the complexity of the data."
      ],
      "metadata": {
        "id": "XLlPUYxI25qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
        "\n",
        "Bias: Bias refers to the error introduced by approximating a real-world problem with a simplified model. High bias models tend to underfit the data.\n",
        "\n",
        "Variance: Variance refers to the models sensitivity to small fluctuations in the training set. High variance models tend to overfit the data.\n",
        "Relationship: The bias-variance tradeoff indicates that as you decrease bias (by increasing model complexity), you typically increase variance, and vice versa. Finding the right balance between bias and variance is crucial for model performance.\n",
        "\n",
        "Impact: High bias leads to underfitting, where the model is too simple to capture the patterns in the data. High variance leads to overfitting, where the model learns noise in the training data and fails to generalize to new data."
      ],
      "metadata": {
        "id": "NjyluJaW25ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n",
        "\n",
        "Overfitting Detection:\n",
        "\n",
        "High training accuracy but low test accuracy.\n",
        "Large gap between training and test performance metrics.\n",
        "Model performs well on training data but poorly on unseen validation or test data.\n",
        "Underfitting Detection:\n",
        "\n",
        "Low training and test accuracy.\n",
        "Model fails to capture patterns or trends present in the data.\n",
        "Consistently poor performance across training, validation, and test datasets."
      ],
      "metadata": {
        "id": "TBkGXsIN25v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?\n",
        "\n",
        "Bias: High bias models are too simple and fail to capture the underlying patterns in the data. Examples include linear regression on nonlinear data.\n",
        "\n",
        "Variance: High variance models are too complex and tend to overfit the training data. Examples include deep neural networks with insufficient regularization.\n",
        "\n",
        "Performance: High bias models have poor performance on both training and test data due to underfitting.\n",
        "High variance models have excellent performance on training data but poor generalization to test data due to overfitting."
      ],
      "metadata": {
        "id": "XaA_cO6j25yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
        "\n",
        "Regularization: Regularization is a technique used to prevent overfitting by adding a penalty term to the models loss function, discouraging large coefficients.\n",
        "\n",
        "Techniques:\n",
        "\n",
        "L1 Regularization (Lasso): Adds the absolute values of coefficients as penalty (λ∑|βi|).\n",
        "L2 Regularization (Ridge): Adds the squared values of coefficients as penalty (λ∑βi²).\n",
        "Elastic Net: Combination of L1 and L2 regularization (λ1∑|βi| + λ2∑βi²).\n",
        "Dropout: Randomly drops neurons during training to reduce interdependence among neurons and prevent overfitting in neural networks."
      ],
      "metadata": {
        "id": "YI47VD5Y250l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABjM3wwg253N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZzzmW4f255V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUVUFwL9258L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyhoSWLt25_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}