{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Regression Assignment_4"
      ],
      "metadata": {
        "id": "C8qtOLxmGWo1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvVlUtM1GBZV"
      },
      "outputs": [],
      "source": [
        "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
        "Lasso Regression:\n",
        "\n",
        "Definition: Lasso (Least Absolute Shrinkage and Selection Operator) Regression is a regularization technique that adds a penalty to the ordinary least squares (OLS) regression objective function.\n",
        "It uses the L1 regularization, which adds a penalty equivalent to the absolute value of the magnitude of coefficients.\n",
        "Difference from Other Techniques:\n",
        "Penalty Type: Lasso Regression uses L1 regularization, which penalizes the sum of the absolute values of the coefficients, leading to sparsity (some coefficients can be exactly zero).\n",
        "Feature Selection: Lasso can perform feature selection by effectively reducing the coefficients of less important predictors to zero."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
        "Advantage:\n",
        "\n",
        "Feature Selection: Lasso Regression can automatically select a subset of predictors by setting the coefficients of less important predictors to zero.\n",
        "Sparse Models: It leads to sparse models with fewer features, which can improve model interpretability and reduce overfitting."
      ],
      "metadata": {
        "id": "fCNOTtgtHVn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
        "Coefficient Interpretation:\n",
        "\n",
        "Non-Zero Coefficients: Non-zero coefficients indicate the importance and direction (positive or negative) of the relationship between each predictor and the response variable.\n",
        "Zero Coefficients: Coefficients that are exactly zero mean that the corresponding predictors have been excluded from the model, implying that these predictors are considered irrelevant by Lasso Regression."
      ],
      "metadata": {
        "id": "oScGwDJKHVv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
        "Tuning Parameters:\n",
        "\n",
        "Regularization Parameter (位): Controls the strength of regularization.\n",
        "Higher 位 values increase the penalty on the coefficients, leading to more coefficients being pushed towards zero.\n",
        "Normalization: Sometimes the predictors are normalized before applying Lasso Regression to ensure all variables are on the same scale.\n",
        "Effect on Performance:\n",
        "\n",
        "Bias-Variance Trade-off: Increasing 位 decreases variance (reduces overfitting) but increases bias.\n",
        "Optimal : Selection of 位 is crucial; it is typically chosen using cross-validation techniques to balance bias and variance for optimal model performance."
      ],
      "metadata": {
        "id": "fRjjp6gmHV0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
        "Non-linear Regression:\n",
        "\n",
        "No: Lasso Regression is inherently a linear regression technique and cannot capture non-linear relationships between predictors and the response variable.\n",
        "Pre-processing: For non-linear relationships, pre-processing techniques like polynomial features or transformations can be applied to the predictors before fitting the Lasso Regression model."
      ],
      "metadata": {
        "id": "SaB8olr7HV3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
        "Differences:\n",
        "\n",
        "Regularization Type: Ridge Regression usesL2 regularization (penalty on the squared magnitude of coefficients), while Lasso uses L1 regularization (penalty on the absolute magnitude of coefficients).\n",
        "\n",
        "Coefficient Shrinkage: Ridge Regression shrinks the coefficients towards zero, while Lasso can shrink coefficients to zero, effectively performing feature selection.\n",
        "\n",
        "Solution Space: Ridge Regression typically leads to more stable solutions in the presence of multicollinearity, whereas Lasso can handle feature selection by eliminating less important predictors."
      ],
      "metadata": {
        "id": "MJH9F-2xHV6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
        "Handling Multicollinearity:\n",
        "\n",
        "Yes: Lasso Regression can handle multicollinearity to some extent by shrinking the coefficients of correlated predictors towards zero.\n",
        "Feature Selection: It effectively selects one of the correlated predictors while setting the coefficients of the others to zero, thus indirectly dealing with multicollinearity."
      ],
      "metadata": {
        "id": "gmEONUv7HV-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
        "Choosing 位:\n",
        "\n",
        "Cross-Validation: Use techniques like k-fold cross-validation to evaluate different values of 位.\n",
        "Grid Search: Perform a grid search over a range of 位 values and select the one that optimizes a chosen performance metric (e.g., minimized mean squared error, maximized R2).\n",
        "Regularization Path: Visualize the regularization path to understand how coefficients change with different 位 values and select based on the trade-off between bias and variance."
      ],
      "metadata": {
        "id": "1cC003d9JNHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5npdu-hJNNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2iVXinWcJNSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2mdXI-XsJNdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}